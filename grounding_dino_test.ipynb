{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grounding DINO Zero-Shot Redaction Detection\n",
    "\n",
    "This notebook tests IDEA-Research/grounding-dino-base for zero-shot detection of black boxes/redactions in document images.\n",
    "\n",
    "**Usage:**\n",
    "1. Run Cell 1 to install dependencies\n",
    "2. Run Cell 2 to load the model\n",
    "3. Update `IMAGE_PATH` in Cell 3 to point to your image\n",
    "4. Run remaining cells to detect and visualize redactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "!pip install transformers torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports & Model Loading\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Load Grounding DINO model and processor\n",
    "model_id = \"IDEA-Research/grounding-dino-base\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Loading model on {device}...\")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Image Loading\n",
    "# Update this path to point to your image\n",
    "IMAGE_PATH = \"/path/to/your/image.png\"\n",
    "\n",
    "image = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "print(f\"Image size: {image.size}\")\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Inference with Multiple Prompts\n",
    "\n",
    "# Detection thresholds\n",
    "box_threshold = 0.25  # Confidence threshold for keeping boxes\n",
    "text_threshold = 0.25  # Confidence threshold for text-box matching\n",
    "\n",
    "# Prompts to test for redaction detection\n",
    "prompts = [\n",
    "    \"black box\",\n",
    "    \"redaction\",\n",
    "    \"redacted text\",\n",
    "    \"black rectangle\",\n",
    "]\n",
    "\n",
    "def run_detection(image, text_prompt, box_thresh, text_thresh):\n",
    "    \"\"\"Run Grounding DINO detection with given prompt and thresholds.\"\"\"\n",
    "    inputs = processor(images=image, text=text_prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    results = processor.post_process_grounded_object_detection(\n",
    "        outputs,\n",
    "        inputs.input_ids,\n",
    "        box_threshold=box_thresh,\n",
    "        text_threshold=text_thresh,\n",
    "        target_sizes=[image.size[::-1]]  # (height, width)\n",
    "    )\n",
    "    \n",
    "    return results[0]\n",
    "\n",
    "# Run detection for each prompt\n",
    "all_results = {}\n",
    "for prompt in prompts:\n",
    "    result = run_detection(image, prompt, box_threshold, text_threshold)\n",
    "    all_results[prompt] = result\n",
    "    num_boxes = len(result[\"boxes\"])\n",
    "    print(f\"Prompt: '{prompt}' -> {num_boxes} detection(s)\")\n",
    "    if num_boxes > 0:\n",
    "        for i, (box, score, label) in enumerate(zip(result[\"boxes\"], result[\"scores\"], result[\"labels\"])):\n",
    "            print(f\"  [{i}] score={score:.3f}, box={box.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualization\n",
    "\n",
    "def visualize_detections(image, results_dict, figsize=(16, 12)):\n",
    "    \"\"\"Visualize detections from all prompts in a grid.\"\"\"\n",
    "    num_prompts = len(results_dict)\n",
    "    cols = 2\n",
    "    rows = (num_prompts + 1) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axes = axes.flatten() if num_prompts > 1 else [axes]\n",
    "    \n",
    "    # Color map based on confidence\n",
    "    cmap = plt.cm.RdYlGn  # Red (low) to Green (high)\n",
    "    \n",
    "    for idx, (prompt, result) in enumerate(results_dict.items()):\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f\"Prompt: '{prompt}' ({len(result['boxes'])} detections)\")\n",
    "        ax.axis(\"off\")\n",
    "        \n",
    "        boxes = result[\"boxes\"]\n",
    "        scores = result[\"scores\"]\n",
    "        \n",
    "        for box, score in zip(boxes, scores):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            # Color based on confidence score\n",
    "            color = cmap(score.item())\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), width, height,\n",
    "                linewidth=2,\n",
    "                edgecolor=color,\n",
    "                facecolor=\"none\"\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add score label\n",
    "            ax.text(\n",
    "                x1, y1 - 5,\n",
    "                f\"{score:.2f}\",\n",
    "                color=color,\n",
    "                fontsize=10,\n",
    "                fontweight=\"bold\",\n",
    "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.7)\n",
    "            )\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(results_dict), len(axes)):\n",
    "        axes[idx].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize all results\n",
    "visualize_detections(image, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 (Optional): Single Prompt with Custom Threshold\n",
    "# Use this cell to experiment with a specific prompt and threshold\n",
    "\n",
    "CUSTOM_PROMPT = \"black box\"  # Change this\n",
    "CUSTOM_BOX_THRESHOLD = 0.20  # Lower = more detections, higher = fewer but more confident\n",
    "CUSTOM_TEXT_THRESHOLD = 0.20\n",
    "\n",
    "custom_result = run_detection(image, CUSTOM_PROMPT, CUSTOM_BOX_THRESHOLD, CUSTOM_TEXT_THRESHOLD)\n",
    "\n",
    "print(f\"Detected {len(custom_result['boxes'])} boxes with prompt '{CUSTOM_PROMPT}'\")\n",
    "\n",
    "# Visualize single result\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.imshow(image)\n",
    "ax.set_title(f\"'{CUSTOM_PROMPT}' (box_thresh={CUSTOM_BOX_THRESHOLD}, text_thresh={CUSTOM_TEXT_THRESHOLD})\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "cmap = plt.cm.RdYlGn\n",
    "for box, score in zip(custom_result[\"boxes\"], custom_result[\"scores\"]):\n",
    "    x1, y1, x2, y2 = box.tolist()\n",
    "    color = cmap(score.item())\n",
    "    rect = patches.Rectangle(\n",
    "        (x1, y1), x2 - x1, y2 - y1,\n",
    "        linewidth=3,\n",
    "        edgecolor=color,\n",
    "        facecolor=\"none\"\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x1, y1 - 5, f\"{score:.2f}\", color=color, fontsize=12, fontweight=\"bold\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
